{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Data import"
      ],
      "metadata": {
        "id": "G0kjuSLx2ojw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpfX2-p22Br0",
        "outputId": "c1973142-d28b-4f30-af8d-42e3a1daebae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.5.18.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Downloading 2022-comp5046-a2.zip to /content\n",
            "  0% 0.00/376k [00:00<?, ?B/s]\n",
            "100% 376k/376k [00:00<00:00, 85.0MB/s]\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Archive:  /content/2022-comp5046-a2.zip\n",
            "  inflating: sample.csv              \n",
            "  inflating: test_without_labels.csv  \n",
            "  inflating: train.csv               \n",
            "  inflating: val.csv                 \n"
          ]
        }
      ],
      "source": [
        "# Import Training data and Testing data\n",
        "# The data is from https://www.kaggle.com/competitions/2022-comp5046-a2/data\n",
        "import numpy as np\n",
        "# Download dataset from kaggle using API provided https://github.com/Kaggle/kaggle-api\n",
        "!pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "# make sure you imported kaggle.json to /content directory\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download -c 2022-comp5046-a2\n",
        "# Unzip dataset\n",
        "!apt install unzip\n",
        "!unzip  /content/2022-comp5046-a2.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read training dataset and dislay 10 samples from it.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "training_data = pd.read_csv('/content/train.csv', encoding = \"ISO-8859-1\")\n",
        "testing_data = pd.read_csv('/content/val.csv', encoding = \"ISO-8859-1\")\n",
        "validation_data = pd.read_csv('/content/test_without_labels.csv', encoding = \"ISO-8859-1\")\n",
        "# training_data.head(10)"
      ],
      "metadata": {
        "id": "H5iIn_HQ4z1n"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare training set and testing set, transfer them to sentence list\n",
        "training_sent = training_data['sents'].tolist()\n",
        "training_label = [label.split(' ') for label in training_data['labels'].tolist()]\n",
        "\n",
        "testing_sent = testing_data['sents'].tolist()\n",
        "testing_label = [label.split(' ') for label in testing_data['labels'].tolist()]\n",
        "\n",
        "validation_sent = testing_data['sents'].tolist()\n",
        "# print(training_sent[:10])\n",
        "# print(training_label[:10])"
      ],
      "metadata": {
        "id": "mf9FTnn046E-"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocess"
      ],
      "metadata": {
        "id": "j5uaFBWFt7Hn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_lowercase(sentences):\n",
        "  return [sentence.lower() for sentence in sentences]\n",
        "def tokenize(sentences):\n",
        "  result = []\n",
        "  for sentence in sentences:\n",
        "    n = sentence.split(' ')\n",
        "    result.append(n)\n",
        "  return result\n",
        "\n",
        "from nltk.stem.snowball import *\n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "def stemming(data):\n",
        "  return [[stemmer.stem(word) for word in sentence] for sentence in data]\n",
        "\n",
        "training_data_after_preprocess = stemming(tokenize(to_lowercase(training_sent)))\n",
        "testing_data_after_preprocess = stemming(tokenize(to_lowercase(testing_sent)))\n",
        "\n",
        "train_data = training_data_after_preprocess\n",
        "target_y_train = training_label\n",
        "validation_data = testing_data_after_preprocess\n",
        "target_y_validation = testing_label\n",
        "\n",
        "# for word embedding\n",
        "corpus = train_data+validation_data\n",
        "# print(len(train_data))\n",
        "# print(len(target_y_train))"
      ],
      "metadata": {
        "id": "nGmTGJ4k5Col"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Embedding"
      ],
      "metadata": {
        "id": "lVZ-1v212tNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# word dict\n",
        "word_to_ix = {}\n",
        "word_to_ix['UNKNOWN'] = 0\n",
        "for sentence in corpus:\n",
        "    for word in sentence:\n",
        "        word = word.lower()\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "word_list = list(word_to_ix.keys())\n",
        "\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "tag_to_ix = {START_TAG:0, STOP_TAG:1}\n",
        "for tags in training_label+testing_label:\n",
        "    for tag in tags:\n",
        "        if tag not in tag_to_ix:\n",
        "            tag_to_ix[tag] = len(tag_to_ix)"
      ],
      "metadata": {
        "id": "TyKxOOOwY-_3"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## POS TAGGING"
      ],
      "metadata": {
        "id": "wDkLYa4AWvYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import pos_tag, word_tokenize\n",
        "def PoS_embedding(corpus):\n",
        "  result = []\n",
        "  for text in corpus:\n",
        "    result.append(nltk.pos_tag(text))\n",
        "  return result;\n",
        "# get a list of sentences with its pos tags\n",
        "pos_taggings = PoS_embedding(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81WAhJTX9ltw",
        "outputId": "5bca93bc-d1d1-4b8e-9f6d-7be8d8e8660d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "pos_word_list = []\n",
        "tag_list = []\n",
        "for i in range(len(pos_taggings)):\n",
        "  for j in range(len(pos_taggings[i])):\n",
        "    pos_word_list.append(pos_taggings[i][j][0])\n",
        "    tag_list.append(pos_taggings[i][j][1])\n",
        "values = array(tag_list)\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "pos_tagging_dict = dict(zip(pos_word_list, onehot_encoded))"
      ],
      "metadata": {
        "id": "Q408yXhAZ_WP"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Domain Feature"
      ],
      "metadata": {
        "id": "BlV4-vhutzxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "\n",
        "EMBEDDING_DIM = 128\n",
        "word_emb_model = FastText(sentences=training_data_after_preprocess+testing_data_after_preprocess, size=EMBEDDING_DIM)\n",
        "embedding_matrix = []\n",
        "for word in word_list:\n",
        "    try:\n",
        "        embedding_matrix.append(word_emb_model.wv[word])\n",
        "    except:\n",
        "        embedding_matrix.append([0]*EMBEDDING_DIM)\n",
        "embedding_matrix = np.array(embedding_matrix)"
      ],
      "metadata": {
        "id": "WGpwthsm5aNE"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "cyberbully_data = pd.read_csv('/content/youtube_parsed_dataset.csv')\n",
        "cyberbully_text = cyberbully_data['Text']\n",
        "cyberbully_sent = cyberbully_data['Text'].tolist()\n",
        "cyberbully_sent[0]\n",
        "cyberbully_text_after_preprocess = stemming(tokenize(to_lowercase(cyberbully_sent)))\n",
        "\n",
        "feature_word_to_ix = {}\n",
        "feature_word_to_ix['UNKNOWN'] = 0\n",
        "for sentence in cyberbully_text_after_preprocess:\n",
        "    for word in sentence:\n",
        "        word = word.lower()\n",
        "        if word not in feature_word_to_ix:\n",
        "            feature_word_to_ix[word] = len(feature_word_to_ix)\n",
        "feature_word_list = list(feature_word_to_ix.keys())\n",
        "\n",
        "\n",
        "EMBEDDING_DIM = 128\n",
        "feature_domain_embedding_model = FastText(sentences=cyberbully_text_after_preprocess, size=EMBEDDING_DIM)\n",
        "feature_domain_embedding_matrix = []\n",
        "for word in feature_word_list:\n",
        "    try:\n",
        "        feature_domain_embedding_matrix.append(feature_domain_embedding_model.wv[word])\n",
        "    except:\n",
        "        feature_domain_embedding_matrix.append([0]*EMBEDDING_DIM)\n",
        "feature_domain_embedding_matrix = np.array(feature_domain_embedding_matrix)\n",
        "feature_domain_embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bnXfTb3aNxU",
        "outputId": "949935a2-8c6d-445a-ce67-19af2176609b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(69270, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Input Concatenation"
      ],
      "metadata": {
        "id": "K1hhaTI3aeFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the final embedding table(should be the combination of 3 aspects)\n",
        "syntactic_textual_model = word_emb_model\n",
        "semantic_textual_model = pos_tagging_dict\n",
        "domain_model = feature_domain_embedding_model\n",
        "\n",
        "# The embedding table would be like a list of dict [{'word1':[word2vec_1]}, {'word2':[word2vec_2]}, {'word1':[word2vec_2]}, {'word1':[word2vec_2]}] so that we can use it in later embedding layer\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "emb_dim1 = word_emb_model.vector_size\n",
        "emb_dim2 = 39\n",
        "emb_dim3 = feature_domain_embedding_model.vector_size\n",
        "\n",
        "# Embedding lookup table via concatenation\n",
        "emb_table_w2v = []\n",
        "for i, word in enumerate(word_list):\n",
        "    if word in word_emb_model:\n",
        "        emb_table_w2v.append(word_emb_model[word])\n",
        "    else:\n",
        "        emb_table_w2v.append([0]*(emb_dim1))\n",
        "emb_table = np.array(emb_table_w2v)\n",
        "\n",
        "# Embedding lookup table via concatenation\n",
        "emb_table_w2v_pos = []\n",
        "\n",
        "for i, word in enumerate(word_list):\n",
        "    if word in word_emb_model and word in pos_tagging_dict:\n",
        "        emb_table_w2v_pos.append(list(semantic_textual_model[word])+list(syntactic_textual_model[word]))\n",
        "    else:\n",
        "        emb_table_w2v_pos.append(np.array([0]*(emb_dim1+emb_dim2)))\n",
        "emb_table_w2v_pos = np.array(emb_table_w2v_pos)\n",
        "\n",
        "# Embedding lookup table via concatenation\n",
        "emb_table_w2v_pos_feature = []\n",
        "for i, word in enumerate(word_list):\n",
        "    if word in word_emb_model and word in pos_tagging_dict and word in feature_domain_embedding_model:\n",
        "\n",
        "        emb_table_w2v_pos_feature.append(list(semantic_textual_model[word])+list(syntactic_textual_model[word])+list(domain_model[word]))\n",
        "    else:\n",
        "        emb_table_w2v_pos_feature.append([0]*(emb_dim1+emb_dim2+emb_dim3))\n",
        "emb_table_w2v_pos_feature = np.array(emb_table_w2v_pos_feature)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAvzUXYZac6k",
        "outputId": "2050d0a8-a307-45b5-eee2-79ab807ecd82"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(emb_table_w2v_pos_feature.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QXNObmrXfwv",
        "outputId": "69f0c9a8-b8cc-424f-f9b3-1fdd8864f228"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9682, 295)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentence Encoding"
      ],
      "metadata": {
        "id": "zNCg8U3G22sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_index(data, to_ix, type):\n",
        "    input_index_list = []\n",
        "    for sent in data:\n",
        "      result = []\n",
        "      for w in sent:\n",
        "        if type == 'tag':\n",
        "          result.append(to_ix[w])\n",
        "        else:\n",
        "          if w in word_list:\n",
        "            result.append(to_ix[w])\n",
        "          else:\n",
        "            result.append(to_ix['UNKNOWN'])\n",
        "      input_index_list.append(result)\n",
        "    return input_index_list\n",
        "\n",
        "train_input_index =  to_index(train_data,word_to_ix,'word')\n",
        "train_output_index = to_index(target_y_train,tag_to_ix,'tag')\n",
        "val_input_index = to_index(validation_data,word_to_ix,'word')\n",
        "val_output_index = to_index(target_y_validation,tag_to_ix,'tag')"
      ],
      "metadata": {
        "id": "kgBRnFkg5kGT"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Data& Test Data\n",
        "\n"
      ],
      "metadata": {
        "id": "HWw_IMYF28p3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seq2Seq Model"
      ],
      "metadata": {
        "id": "Fy2AzcAT3TUg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Define"
      ],
      "metadata": {
        "id": "TV8K3wbJFcEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "LMleszKOOFvR"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "GD-glGBe3ZqO"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BiLSTM Encoder"
      ],
      "metadata": {
        "id": "AipOMSfSuEeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM Encoder\n",
        "# input -> torch.Size([seq_length, embedding_size]) \n",
        "# output -> torch.Size([seq_length, hidden_size*2])\n",
        "# final_hidden -> torch.Size([layers_num*2, hidden_size])\n",
        "## Encoder LSTM\n",
        "\n",
        "class LstmEncoder(nn.Module):\n",
        "  def __init__(self, hidden_size, layers_num, word_embedding_matrix):\n",
        "    super(LstmEncoder, self).__init__()\n",
        "    self.bidirectional = True\n",
        "    self.word_embeds = nn.Embedding(word_embedding_matrix.shape[0], word_embedding_matrix.shape[1])\n",
        "    self.word_embeds.weight.data.copy_(torch.from_numpy(word_embedding_matrix))\n",
        "    self.hidden_dim = hidden_size\n",
        "    self.layers_num = layers_num\n",
        "    self.lstm = nn.LSTM(word_embedding_matrix.shape[1], hidden_size, num_layers=layers_num, \n",
        "                        bidirectional=self.bidirectional)\n",
        "\n",
        "  def forward(self, input, hidden, cell):\n",
        "    input = self.word_embeds(input)\n",
        "    output, (final_hidden, final_cell) = self.lstm(input, (hidden, cell))\n",
        "    return output, final_hidden, final_cell"
      ],
      "metadata": {
        "id": "mHj1DloDFfBt"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BiLSTM Decoder"
      ],
      "metadata": {
        "id": "fdkf526HuG__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM Decoder\n",
        "## Decoder LSTM\n",
        "\n",
        "class LstmDecoder(nn.Module):\n",
        "  def __init__(self, hidden_size, embedding_size, layers_num):\n",
        "    super(LstmDecoder, self).__init__()\n",
        "    self.bidirectional = True\n",
        "    self.hidden_dim = hidden_size\n",
        "    self.layers_num = layers_num\n",
        "    self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers=layers_num, \n",
        "                        bidirectional=self.bidirectional)\n",
        "\n",
        "  def forward(self, input, hidden, cell):\n",
        "    output, (final_hidden, final_cell) = self.lstm(input, (hidden, cell))\n",
        "    return output, final_hidden, final_cell"
      ],
      "metadata": {
        "id": "F1CyBeUh4C3d"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BiLSTM with CRF Model"
      ],
      "metadata": {
        "id": "7l-gkvxSuLCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "\n",
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, tag_to_ix, hidden_dim, word_embedding_matrix, layers_num, with_crf, use_baseline, attention_method):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.with_crf = with_crf\n",
        "        self.use_baseline = use_baseline\n",
        "        self.attention_method = attention_method\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        self.layers_num = layers_num\n",
        "        self.bidirectional = True\n",
        "        self.lstm = LstmEncoder(hidden_dim, layers_num, word_embedding_matrix)\n",
        "\n",
        "        self.decoder = LstmDecoder(hidden_dim, hidden_dim*2*(self.layers_num+1), layers_num)\n",
        "        self.attention_size = self.hidden_dim        # just for vT * tanh(W1h+W2s)\n",
        "        self.v = torch.rand(1, self.attention_size, requires_grad=True)\n",
        "\n",
        "        self.attention_W1 = nn.Linear(2*self.layers_num*self.hidden_dim,self.hidden_dim)\n",
        "        self.attention_W2 = nn.Linear(2*self.layers_num*self.hidden_dim,self.hidden_dim)\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim * 2, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "        self.hidden, self.cell = self.init_hidden()\n",
        "\n",
        "\n",
        "    def init_hidden(self):\n",
        "      n = 1\n",
        "      if self.bidirectional:\n",
        "        n = 2\n",
        "      return (torch.zeros(n*self.layers_num,self.hidden_dim), torch.zeros(n*self.layers_num,self.hidden_dim))\n",
        "        \n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        # encoding sentence and get memory, final hidden state\n",
        "\n",
        "        encoder_hidden, encoder_cell = self.init_hidden()\n",
        "        # memory is each step hidden state(output) seq_length * (2 hidden_dim)\n",
        "        # final_hidden \n",
        "        memory, final_hidden, final_cell = self.lstm(sentence, self.hidden, self.cell) \n",
        "\n",
        "        if self.use_baseline:\n",
        "          lstm_feats = self.hidden2tag(memory)\n",
        "          return lstm_feats\n",
        "        else:\n",
        "          # attention weight\n",
        "          \n",
        "\n",
        "          # attn_weight = F.softmax(torch.bmm(final_hidden.reshape(1,-1).unsqueeze(0),memory.repeat(1,self.layers_num).unsqueeze(0).permute(0,2,1)).squeeze(0),1)\n",
        "          attn_weight = self._calculate_attention(final_hidden, memory)\n",
        "\n",
        "          # decoder sentence with the memory and final hidden state\n",
        "          deocder_outputs = torch.zeros(sentence.size()[0], self.hidden_dim*2)\n",
        "          decoder_hidden = final_hidden\n",
        "          decoder_cell = encoder_cell\n",
        "          for di in range(sentence.size(0)):\n",
        "            context = torch.bmm(attn_weight.unsqueeze(0),memory.unsqueeze(0)).squeeze(0)      #context\n",
        "            decoder_input = torch.cat((decoder_hidden.reshape(1,-1),context), dim=1)        # concenate context with hidden state\n",
        "            # print(decoder_input.size())\n",
        "            decoder_output, decoder_hidden, decoder_cell = self.decoder(decoder_input, decoder_hidden, decoder_cell)\n",
        "            # decoder_input = decoder_output\n",
        "            deocder_outputs[di] = decoder_output\n",
        "            # attn_weight = F.softmax(torch.bmm(decoder_output.unsqueeze(0),memory.unsqueeze(0).permute(0,2,1)).squeeze(0),1)\n",
        "            attn_weight = self._calculate_attention(decoder_hidden, memory)\n",
        "\n",
        "          lstm_feats = self.hidden2tag(deocder_outputs)\n",
        "          return lstm_feats\n",
        "\n",
        "    def _calculate_attention(self, input, memory):\n",
        "        # input is like query vector\n",
        "        # memory is from encoder\n",
        "        input = input.reshape(1,-1).unsqueeze(0)\n",
        "        # print(input.size())\n",
        "        # seq_length * (hidden_dim*2)   8*100 but here we need to repeat them to 8*layers*2*hidden\n",
        "        memory = memory.repeat(1,self.layers_num).unsqueeze(0).permute(0,2,1)\n",
        "        # print(memory.size())\n",
        "        if self.attention_method == 1:       # dot product\n",
        "          attn_weight = torch.bmm(input, memory).squeeze(0)\n",
        "          attn_weight = F.softmax(attn_weight, dim=1)\n",
        "          return attn_weight\n",
        "        if self.attention_method == 2:       # scaled dot product\n",
        "          scale = 1.0/np.sqrt(input.size()[1])\n",
        "          attn_weight = torch.bmm(input, memory).squeeze(0) * scale\n",
        "          attn_weight = F.softmax(attn_weight, dim=1)\n",
        "          return attn_weight\n",
        "        else:                  # tanh\n",
        "          part_h = self.attention_W1(memory.permute(0,2,1))\n",
        "          part_s = self.attention_W2(input)\n",
        "          part_s = part_s.repeat(1,part_h.size()[1],1)\n",
        "          attn_weight = torch.bmm(self.v.unsqueeze(0), torch.tanh(part_h + part_s).permute(0,2,1)).squeeze(0)\n",
        "          attn_weight = F.softmax(attn_weight, dim=1)\n",
        "          return attn_weight\n",
        "\n",
        "\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def crossEntropyLoss(self, sentence, tags):\n",
        "        criteria = nn.CrossEntropyLoss()\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        return criteria(feats, tags)\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "        without_crf_seq = F.softmax(lstm_feats, dim=1)\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        if self.with_crf:\n",
        "          return score, tag_seq\n",
        "        else:\n",
        "          return torch.argmax(without_crf_seq,dim=1)"
      ],
      "metadata": {
        "id": "RDHpIazNFbpk"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate Accuracy"
      ],
      "metadata": {
        "id": "XL3LbnwwuVE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "def cal_acc(model, input_index, output_index):\n",
        "    ground_truth = []\n",
        "    predicted = []\n",
        "    for i,idxs in enumerate(input_index):\n",
        "        ground_truth += output_index[i]\n",
        "        if model.with_crf:\n",
        "          score, pred = model(torch.tensor(idxs, dtype=torch.long).to(device))\n",
        "        else:\n",
        "          pred = model(torch.tensor(idxs, dtype=torch.long).to(device))\n",
        "        predicted += pred\n",
        "    accuracy = sum(np.array(ground_truth) == np.array(predicted))/len(ground_truth)\n",
        "    score = f1_score(ground_truth, predicted, average='weighted')\n",
        "    return predicted, ground_truth, accuracy, score"
      ],
      "metadata": {
        "id": "1iU0U_P5xMys"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tran Model"
      ],
      "metadata": {
        "id": "L5eExeXIuZye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "\n",
        "import datetime\n",
        "def train(model, combination):\n",
        "  f1_score = 0\n",
        "  for epoch in range(EPOCH):  \n",
        "      time1 = datetime.datetime.now()\n",
        "      train_loss = 0\n",
        "\n",
        "      model.train()\n",
        "      for i, idxs in enumerate(train_input_index):\n",
        "          tags_index = train_output_index[i]\n",
        "          # Step 1. Remember that Pytorch accumulates gradients.\n",
        "          # We need to clear them out before each instance\n",
        "          model.zero_grad()\n",
        "\n",
        "          # Step 2. Get our inputs ready for the network, that is,\n",
        "          # turn them into Tensors of word indices.\n",
        "          sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "          # print(sentence_in.size())\n",
        "          # print(sentence_in.view(1,-1).size())\n",
        "          targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "          # Step 3. Run our forward pass.\n",
        "          if WITH_CRF:\n",
        "            loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "          else:\n",
        "            loss = model.crossEntropyLoss(sentence_in, targets)\n",
        "          # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "          # calling optimizer.step()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          train_loss+=loss.item()\n",
        "          # if i%200 == 0:\n",
        "          #   print(\"Epoch:%d, Batch number: %d, tol number: %d\" %(epoch+1, i, len(train_input_index)))\n",
        "          # break\n",
        "      model.eval()\n",
        "      # for i in train_input_index:\n",
        "        # print(type(i))\n",
        "      # train_input_index_eval = [torch.tensor(sentence, dtype=torch.long).view(1,-1) for sentence in train_input_index]\n",
        "      # val_input_index_eval = [torch.tensor(sentence, dtype=torch.long).view(1,-1) for sentence in val_input_index]\n",
        "      # Call the cal_acc functions you implemented as required\n",
        "      _, _, train_acc, train_f1 = cal_acc(model,train_input_index,train_output_index)\n",
        "      _, _, val_acc, val_f1 = cal_acc(model,val_input_index,val_output_index)\n",
        "\n",
        "      val_loss = 0\n",
        "      for i, idxs in enumerate(val_input_index):\n",
        "          tags_index = val_output_index[i]\n",
        "          sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "          targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "          loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "          val_loss+=loss.item()\n",
        "      time2 = datetime.datetime.now()\n",
        "      f1_score = val_f1\n",
        "      print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "  print('Validation F1 Score: '+ str(f1_score))\n",
        "  torch.save(model, combination+'.pt')\n",
        "\n",
        "# The log below is the sample output for this section\n",
        "# Please make sure you keep your own running log for submission"
      ],
      "metadata": {
        "id": "PVMfBatwwyhX"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Word_Embedding_Model = emb_table_w2v_pos        # emb_table, emb_table_w2v_pos, emb_table_w2v_pos_feature\n",
        "VOCAB_SIZE = Word_Embedding_Model.shape[0]\n",
        "EMBEDDING_DIM = Word_Embedding_Model.shape[1]\n",
        "HIDDEN_SIZE = 50\n",
        "LAYER_NUM = 1\n",
        "OUTPUT_SIZE = len(tag_to_ix)                  # 9\n",
        "MAX_SEQ_LENGTH = max(len(i) for i in train_input_index)  # 57\n",
        "ATTENTION_METHOD = 3\n",
        "EPOCH = 2\n",
        "WITH_CRF = True\n",
        "USE_BASELINE = True\n",
        "#tag_to_ix, hidden_dim, word_embedding_matrix, layers_num, with_crf, use_baseline, attention_method\n"
      ],
      "metadata": {
        "id": "rKNFmwCw0rgz"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = ['O','T','P','SEPA','S','D','C']"
      ],
      "metadata": {
        "id": "usl51zqvnFev"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Test the model"
      ],
      "metadata": {
        "id": "2rbdJeGn1Ue4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test for word embedding\n",
        "# fastText\n",
        "# tag_to_ix, hidden_dim, word_embedding_matrix, layers_num, with_crf, use_baseline, attention_method\n",
        "model = BiLSTM_CRF(tag_to_ix=tag_to_ix, \n",
        "          hidden_dim=50, \n",
        "          word_embedding_matrix=emb_table, \n",
        "          layers_num=1, \n",
        "          with_crf=True, \n",
        "          use_baseline=True, \n",
        "          attention_method=1).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "train(model, 'baseline_word2vec')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xs9JevFfIc_7",
        "outputId": "ec89c52d-a042-49bc-f8b4-bc8fc969b515"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1, Training loss: 29293.42, train acc: 0.9805, val loss: 2697.69, val acc: 0.9785, time: 557.60s\n",
            "Epoch:2, Training loss: 4934.80, train acc: 0.9916, val loss: 1745.01, val acc: 0.9879, time: 563.09s\n",
            "Validation F1 Score: 0.9879031482732025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('baseline_word2vec.pt')\n",
        "predicted, ground_truth, accuracy, score = cal_acc(model,val_input_index,val_output_index)\n",
        "print(classification_report(ground_truth, predicted, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rW1j1OkXnSZF",
        "outputId": "dd54ebdb-2c8e-404d-fa2a-6ae57e33449f"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.99      0.99      0.99     18985\n",
            "           T       0.98      0.97      0.97      1469\n",
            "           P       1.00      1.00      1.00      3936\n",
            "        SEPA       1.00      1.00      1.00      3603\n",
            "           S       0.97      0.97      0.97      3322\n",
            "           D       0.92      0.90      0.91       398\n",
            "           C       0.98      0.98      0.98      1641\n",
            "\n",
            "    accuracy                           0.99     33354\n",
            "   macro avg       0.98      0.97      0.97     33354\n",
            "weighted avg       0.99      0.99      0.99     33354\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test for word embedding\n",
        "# fastText+POS\n",
        "# tag_to_ix, hidden_dim, word_embedding_matrix, layers_num, with_crf, use_baseline, attention_method\n",
        "model = BiLSTM_CRF(tag_to_ix=tag_to_ix, \n",
        "          hidden_dim=50, \n",
        "          word_embedding_matrix=emb_table_w2v_pos, \n",
        "          layers_num=1, \n",
        "          with_crf=True, \n",
        "          use_baseline=True, \n",
        "          attention_method=1).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "train(model, 'baseline_word2vec_pos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j591n_0NmxQ5",
        "outputId": "33f78d42-78b4-40fc-db78-b964a07424ef"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1, Training loss: 24806.16, train acc: 0.9837, val loss: 2358.55, val acc: 0.9818, time: 598.88s\n",
            "Epoch:2, Training loss: 4546.99, train acc: 0.9914, val loss: 1814.33, val acc: 0.9877, time: 576.09s\n",
            "Validation F1 Score: 0.9876530994618894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('baseline_word2vec_pos.pt')\n",
        "predicted, ground_truth, accuracy, score = cal_acc(model,val_input_index,val_output_index)\n",
        "print(classification_report(ground_truth, predicted, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3wzrDoInXN0",
        "outputId": "1d1961ce-0910-4c4c-b1cc-ba14dbf22ce7"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.99      0.99      0.99     18985\n",
            "           T       0.98      0.97      0.97      1469\n",
            "           P       1.00      1.00      1.00      3936\n",
            "        SEPA       1.00      1.00      1.00      3603\n",
            "           S       0.97      0.97      0.97      3322\n",
            "           D       0.92      0.89      0.91       398\n",
            "           C       0.98      0.98      0.98      1641\n",
            "\n",
            "    accuracy                           0.99     33354\n",
            "   macro avg       0.98      0.97      0.97     33354\n",
            "weighted avg       0.99      0.99      0.99     33354\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test for word embedding\n",
        "# fastText+POS\n",
        "# tag_to_ix, hidden_dim, word_embedding_matrix, layers_num, with_crf, use_baseline, attention_method\n",
        "model = BiLSTM_CRF(tag_to_ix=tag_to_ix, \n",
        "          hidden_dim=50, \n",
        "          word_embedding_matrix=emb_table_w2v_pos_feature, \n",
        "          layers_num=1, \n",
        "          with_crf=True, \n",
        "          use_baseline=True, \n",
        "          attention_method=1).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "train(model, 'baseline_word2vec_pos_domain')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzV625ccm4Wj",
        "outputId": "499c0fb5-876a-49fa-98e4-14ca98b0d2b9"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1, Training loss: 22456.81, train acc: 0.9769, val loss: 2919.05, val acc: 0.9744, time: 728.57s\n",
            "Epoch:2, Training loss: 5404.35, train acc: 0.9903, val loss: 1872.08, val acc: 0.9863, time: 723.99s\n",
            "Validation F1 Score: 0.9862201854073053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('baseline_word2vec_pos_domain.pt')\n",
        "predicted, ground_truth, accuracy, score = cal_acc(model,val_input_index,val_output_index)\n",
        "print(classification_report(ground_truth, predicted, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1NiV1DFnuXw",
        "outputId": "69a9b2da-dc87-4a5e-d589-921585487e71"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.99      0.99      0.99     18985\n",
            "           T       0.97      0.96      0.97      1469\n",
            "           P       1.00      1.00      1.00      3936\n",
            "        SEPA       1.00      1.00      1.00      3603\n",
            "           S       0.97      0.96      0.97      3322\n",
            "           D       0.91      0.86      0.88       398\n",
            "           C       0.98      0.97      0.98      1641\n",
            "\n",
            "    accuracy                           0.99     33354\n",
            "   macro avg       0.97      0.96      0.97     33354\n",
            "weighted avg       0.99      0.99      0.99     33354\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test for attention\n",
        "# Dot product attention\n",
        "# tag_to_ix, hidden_dim, word_embedding_matrix, layers_num, with_crf, use_baseline, attention_method\n",
        "model = BiLSTM_CRF(tag_to_ix=tag_to_ix, \n",
        "          hidden_dim=50, \n",
        "          word_embedding_matrix=emb_table_w2v_pos_feature, \n",
        "          layers_num=1, \n",
        "          with_crf=True, \n",
        "          use_baseline=False, \n",
        "          attention_method=1).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "train(model, 'fastText_dot_product_attn')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPKmxArD3Ger",
        "outputId": "c862758a-71a9-4aa0-c0b9-3e2ea2a573d6"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1, Training loss: 73686.96, train acc: 0.8323, val loss: 16010.16, val acc: 0.8260, time: 1005.66s\n",
            "Epoch:2, Training loss: 36076.14, train acc: 0.9114, val loss: 9992.22, val acc: 0.9027, time: 1026.19s\n",
            "Validation F1 Score: 0.8974388813789972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('fastText_dot_product_attn.pt')\n",
        "predicted, ground_truth, accuracy, score = cal_acc(model,val_input_index,val_output_index)\n",
        "print(classification_report(ground_truth, predicted, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PT6w9TKn3iO",
        "outputId": "96c84e69-c847-4b8b-e811-f9619f9177d4"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.91      0.96      0.93     18985\n",
            "           T       0.87      0.82      0.85      1469\n",
            "           P       0.92      0.82      0.87      3936\n",
            "        SEPA       0.89      0.87      0.88      3603\n",
            "           S       0.94      0.88      0.91      3322\n",
            "           D       0.94      0.04      0.07       398\n",
            "           C       0.77      0.86      0.81      1641\n",
            "\n",
            "    accuracy                           0.90     33354\n",
            "   macro avg       0.89      0.75      0.76     33354\n",
            "weighted avg       0.90      0.90      0.90     33354\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test for attention\n",
        "# Scaled Dot product attention\n",
        "# tag_to_ix, hidden_dim, word_embedding_matrix, layers_num, with_crf, use_baseline, attention_method\n",
        "model = BiLSTM_CRF(tag_to_ix=tag_to_ix, \n",
        "          hidden_dim=50, \n",
        "          word_embedding_matrix=emb_table, \n",
        "          layers_num=1, \n",
        "          with_crf=True, \n",
        "          use_baseline=False, \n",
        "          attention_method=2).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "train(model, 'fastText_scaled_dot_product_attn')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk9OZsbv3Tz6",
        "outputId": "dc35121f-0a20-4514-9460-575187814d22"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1, Training loss: 72002.44, train acc: 0.8716, val loss: 13303.04, val acc: 0.8649, time: 981.77s\n",
            "Epoch:2, Training loss: 34056.31, train acc: 0.8651, val loss: 14032.07, val acc: 0.8586, time: 995.24s\n",
            "Validation F1 Score: 0.8522524238648989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('fastText_scaled_dot_product_attn.pt')\n",
        "predicted, ground_truth, accuracy, score = cal_acc(model,val_input_index,val_output_index)\n",
        "print(classification_report(ground_truth, predicted, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4jakA1joIhT",
        "outputId": "c8918a2b-5672-44f8-f9d5-f98a8d0b4434"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.89      0.92      0.91     18985\n",
            "           T       0.83      0.75      0.78      1469\n",
            "           P       0.73      0.81      0.77      3936\n",
            "        SEPA       0.91      0.83      0.87      3603\n",
            "           S       0.79      0.89      0.83      3322\n",
            "           D       1.00      0.00      0.01       398\n",
            "           C       0.86      0.57      0.69      1641\n",
            "\n",
            "    accuracy                           0.86     33354\n",
            "   macro avg       0.86      0.68      0.69     33354\n",
            "weighted avg       0.86      0.86      0.85     33354\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test for attention\n",
        "# Bahdanau attention\n",
        "# tag_to_ix, hidden_dim, word_embedding_matrix, layers_num, with_crf, use_baseline, attention_method\n",
        "model = BiLSTM_CRF(tag_to_ix=tag_to_ix, \n",
        "          hidden_dim=50, \n",
        "          word_embedding_matrix=emb_table, \n",
        "          layers_num=1, \n",
        "          with_crf=True, \n",
        "          use_baseline=False, \n",
        "          attention_method=3).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "train(model, 'fastText_Bahdanau_attn')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GTJ3MGQ3WRQ",
        "outputId": "f8a5acee-2b80-4115-dbb1-b2049120e904"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1, Training loss: 74585.16, train acc: 0.8636, val loss: 13048.20, val acc: 0.8596, time: 1030.44s\n",
            "Epoch:2, Training loss: 29108.64, train acc: 0.8721, val loss: 17604.20, val acc: 0.8695, time: 1025.33s\n",
            "Validation F1 Score: 0.8646863275922325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('fastText_Bahdanau_attn.pt')\n",
        "predicted, ground_truth, accuracy, score = cal_acc(model,val_input_index,val_output_index)\n",
        "print(classification_report(ground_truth, predicted, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSNPVgnYoidh",
        "outputId": "c9d7747e-2437-41c8-8ded-ca4ff88f655e"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.89      0.94      0.91     18985\n",
            "           T       0.81      0.73      0.77      1469\n",
            "           P       0.82      0.78      0.80      3936\n",
            "        SEPA       0.82      0.80      0.81      3603\n",
            "           S       0.94      0.84      0.89      3322\n",
            "           D       0.77      0.10      0.18       398\n",
            "           C       0.80      0.79      0.79      1641\n",
            "\n",
            "    accuracy                           0.87     33354\n",
            "   macro avg       0.84      0.71      0.74     33354\n",
            "weighted avg       0.87      0.87      0.86     33354\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test for stack layers 2 LAYERS\n",
        "# Bahdanau attention\n",
        "# tag_to_ix, hidden_dim, word_embedding_matrix, layers_num, with_crf, use_baseline, attention_method\n",
        "model = BiLSTM_CRF(tag_to_ix=tag_to_ix, \n",
        "          hidden_dim=50, \n",
        "          word_embedding_matrix=emb_table, \n",
        "          layers_num=2, \n",
        "          with_crf=True, \n",
        "          use_baseline=False, \n",
        "          attention_method=1).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "train(model, 'fastText_dot_product_attn_2layers')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_p2l9JePRgr",
        "outputId": "f6adbdd3-f0aa-4215-c42f-1f6a0f6bec61"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1, Training loss: 111052.31, train acc: 0.7566, val loss: 23950.70, val acc: 0.7550, time: 988.88s\n",
            "Epoch:2, Training loss: 48665.40, train acc: 0.8637, val loss: 14111.33, val acc: 0.8605, time: 967.81s\n",
            "Validation F1 Score: 0.8518655995462657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('fastText_dot_product_attn_2layers.pt')\n",
        "predicted, ground_truth, accuracy, score = cal_acc(model,val_input_index,val_output_index)\n",
        "print(classification_report(ground_truth, predicted, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZObkKOORo6gd",
        "outputId": "4a24a479-b08a-427d-ed1c-5f877f80389d"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.88      0.96      0.92     18985\n",
            "           T       0.48      0.49      0.49      1469\n",
            "           P       0.91      0.82      0.86      3936\n",
            "        SEPA       0.92      0.82      0.87      3603\n",
            "           S       0.90      0.84      0.87      3322\n",
            "           D       0.00      0.00      0.00       398\n",
            "           C       0.53      0.42      0.47      1641\n",
            "\n",
            "    accuracy                           0.86     33354\n",
            "   macro avg       0.66      0.62      0.64     33354\n",
            "weighted avg       0.85      0.86      0.85     33354\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test for without CRF\n",
        "# Bahdanau attention\n",
        "# tag_to_ix, hidden_dim, word_embedding_matrix, layers_num, with_crf, use_baseline, attention_method\n",
        "model = BiLSTM_CRF(tag_to_ix=tag_to_ix, \n",
        "          hidden_dim=50, \n",
        "          word_embedding_matrix=emb_table, \n",
        "          layers_num=1, \n",
        "          with_crf=False, \n",
        "          use_baseline=False, \n",
        "          attention_method=1).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "train(model, 'fastText_dot_product_attn_1layers_withoutcrf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBZwsr1lTWH9",
        "outputId": "d78479f3-0f68-439a-b3d6-2447f34b06b6"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1, Training loss: 87461.89, train acc: 0.8564, val loss: 13360.14, val acc: 0.8492, time: 767.11s\n",
            "Epoch:2, Training loss: 44315.81, train acc: 0.7809, val loss: 18999.40, val acc: 0.7756, time: 799.26s\n",
            "Validation F1 Score: 0.775821488048554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('fastText_dot_product_attn_1layers_withoutcrf.pt')\n",
        "predicted, ground_truth, accuracy, score = cal_acc(model,val_input_index,val_output_index)\n",
        "print(classification_report(ground_truth, predicted, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvaUk7kXpciC",
        "outputId": "a91052cc-af8d-495f-bf03-15bb4f876b9f"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.87      0.84      0.86     18985\n",
            "           T       0.43      0.72      0.54      1469\n",
            "           P       0.72      0.74      0.73      3936\n",
            "        SEPA       0.60      0.69      0.64      3603\n",
            "           S       0.83      0.76      0.80      3322\n",
            "           D       0.00      0.00      0.00       398\n",
            "           C       0.66      0.55      0.60      1641\n",
            "\n",
            "    accuracy                           0.78     33354\n",
            "   macro avg       0.59      0.62      0.60     33354\n",
            "weighted avg       0.78      0.78      0.78     33354\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save(model, 'mymodel.pt')\n",
        "# the_saved_model = torch.load('mymodel.pt')\n",
        "# ix_tag = {\n",
        "#     0:'<START>',\n",
        "#     1:'<STOP>',\n",
        "#     2:'O',\n",
        "#     3:'T',\n",
        "#     4:'P',\n",
        "#     5:'SEPA',\n",
        "#     6:'S',\n",
        "#     7:'D',\n",
        "#     8:'C'\n",
        "# }\n",
        "\n",
        "# text = 'retard' #@param {type:\"string\"}\n",
        "# result = []\n",
        "# # try:\n",
        "# data_after_preprocessing = tokenize(to_lowercase([text]))\n",
        "# data_encoded = to_index(data_after_preprocessing,word_to_ix,'word')\n",
        "# # print(torch.tensor(data_encoded[0], dtype=torch.long))\n",
        "# # print(torch.tensor(train_input_index[5]))\n",
        "# predit = the_saved_model(torch.tensor(data_encoded[0], dtype=torch.long)).tolist()\n",
        "# result.append([ix_tag[ix] for ix in predit])\n",
        "# print(result)\n",
        "# # except:\n",
        "# #   print('error')\n"
      ],
      "metadata": {
        "id": "ZB9TKC2hMThq"
      },
      "execution_count": 112,
      "outputs": []
    }
  ]
}